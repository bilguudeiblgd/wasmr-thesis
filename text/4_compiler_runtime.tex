\chapter{Compiler and Runtime}
\label{chapter:compiler}
This chapter describes implementation of the compilers, highlighting important challenges and decisions made through
compilation of Typed R to WASM. All implementation related to compiling and its scripts are written in Rust language.
Rust is chosen for its modern features, memory safety and performance. In coming sections,
we'll describe the architecture, and design decisions about the implementation of the compiler.
\section{Compiler Architecture}
Most compilers follow pass-based implementation. To make sense of the complexity,
we divide compiler into so-called front-end, middle-end, and back-end. Front-end includes
everything related to actually taking the code as a string and creating AST tree, and then 
intermediate representation. Middle-end is used for mostly language-independent optimizations 
on the IR. Then, finally the backend, back-end takes that IR and generates target-specific 
binaries or bytecode. In our case back-end would be generating the WASM code.

Conceptually, each part is composed of multiple modules shown in figure below \ref{fig:compiler-pipeline}
.
\paragraph{Front-end}
Composed of Lexer and Parser, it handles syntactic analysis and semantic analysis. Lexer takes in a source code as string,
then produces so-called Tokens that programmer has defined. Those tokens are later fed into Parser, which uses the grammar to 
create AST tree.
\paragraph{Middle-end}
This is where the optimizations happen. Or it could simply translate the IR into more efficient forms for back-end.
\paragraph{Back-end}
Part that's concerned with only generating code for target architecture.
\begin{figure}[h]
\centering
\begin{tikzpicture}[
    node distance=1.5cm,
    box/.style={rectangle, draw, minimum width=2.5cm, minimum height=1cm, align=center, rounded corners},
    phase/.style={rectangle, draw=none, font=\small\itshape, align=center},
    arrow/.style={->, >=stealth, thick}
]

% Front-end
\node[phase] (frontend) {Front-end};
\node[box, below=0.3cm of frontend] (lexer) {Lexer};
\node[box, below of=lexer] (parser) {Parser};
\node[box, below of=parser] (ir) {IR Generation};

% Middle-end
\node[phase, below=1.5cm of ir] (middleend) {Middle-end};
\node[box, below=0.3cm of middleend] (opt) {Optimization\\Passes};

% Back-end
\node[phase, below=1.5cm of opt] (backend) {Back-end};
\node[box, below=0.3cm of backend] (codegen) {Code Generation\\(WASM)};

% Arrows
\draw[arrow] (lexer) -- (parser);
\draw[arrow] (parser) -- (ir);
\draw[arrow] (ir) -- (opt);
\draw[arrow] (opt) -- (codegen);

% Input/Output labels
\node[left=0.8cm of lexer, font=\small] {Source Code};
\draw[->, dashed] ($(lexer.west) + (-0.5,0)$) -- (lexer.west);

\node[left=0.8cm of codegen, font=\small] {WASM Bytecode};
\draw[->, dashed] (codegen.east) -- ($(codegen.east) + (0.5,0)$);

% Phase boundaries
\draw[dashed, gray] ($(ir.south) + (-3,-.75)$) -- ($(ir.south) + (3,-.75)$);
\draw[dashed, gray] ($(opt.south) + (-3,-.75)$) -- ($(opt.south) + (3,-.75)$);

\end{tikzpicture}
\caption{Compiler pipeline architecture showing front-end, middle-end, and back-end phases}
\label{fig:compiler-pipeline}
\end{figure}

\paragraph{Compiler source code}
The compiler uses multi-pass architecture. The contents of source is also available at \ref{source-code-structure}

\subparagraph{Stage 1: Scanning}
The lexer (\texttt{src/lexer.rs}) tokenizes source text into a stream of tokens. It recognizes R-specific operators (\texttt{<-}, \texttt{<<-}, \texttt{:}), tags built-in type names as \texttt{Token::Type}, and supports string interpolation.

\subparagraph{Stage 2: Syntactic Analysis}
The parser (\texttt{src/parser/}) constructs an untyped Abstract Syntax Tree (AST) using a recursive descent parser\cite{recursive-descent-parser} with operator precedence. Expression parsing handles function definitions as expressions, and type annotations are parsed but not validated. The parser produces \texttt{Stmt} and \texttt{Expr} nodes defined in \texttt{src/ast.rs}.

\subparagraph{Stage 3: Type Resolution and IR Construction}
The \texttt{TypeResolver} (\texttt{src/ir/type\_resolver.rs}) performs scope analysis by building a scope stack where only functions create scopes, infers types for untyped expressions, validates type annotations and operation compatibility, and produces typed IR nodes with concrete types. The IR (\texttt{src/ir/types.rs}) consists of \texttt{IRExpr} (expressions with associated \texttt{ty: Type} field), \texttt{IRStmt} (statements with type information), and built-in call resolution to \texttt{BuiltinKind} enum.

\subparagraph{Stage 4: IR Transformation Passes}
A pass manager \newline(\texttt{src/ir/passes/manager.rs}) coordinates three transformation passes. The \textbf{Variable Collection Pass} (\texttt{variable\_collection.rs}) assigns WASM local indices to all variables, tracks parameters, user variables, and compiler-generated temporaries, and populates \texttt{FunctionMetadata} for each function. The \textbf{Captured Variables Analysis} (\texttt{captured\_vars.rs}) identifies variables captured from parent scopes, computes transitive captures through nested functions, and marks variables requiring reference cells for superassignment. The \textbf{Function Flattening Pass} (\texttt{function\_flattening.rs}) lifts nested functions to top level, replaces them with closure construction expressions, and maintains capture lists for environment building.

\subparagraph{Stage 5: Code Generation}
The backend (\texttt{src/backend/}) generates WebAssembly where \texttt{WasmGenerator} constructs WASM module sections, registers type sections for structs, arrays, and functions, emits function code with local context tracking, and initializes memory for runtime data.

\section{WebAssembly Code Generation}
There's not many examples or implementation of a language directly compiling to WASM and it's for a good reason.
Since the dawn of the programming, we've always had middle-layer or common-ground between compilers and bytecodes. Without it,
we have ourselves N x M explosion. Imagine every programming language have to implement and finetune support for 
every architecture there is, from x86 to ARM, to WASM. To avoid this problem we have middle ground representations 
like bytecode, which is an intermediate, platform-independent code that can be easily compiled to different architectures. Or more commonly,
LLVM\cite{llvm}, which a lot of languages use to compile to, helps programmers great deal. Just compile to LLVM IR generation,
and use LLVM to generate any type of low-level code. This is how some static languages run in WASM. Also, JVM also built support for
WASM so that JVM-based languages all can compile to WASM. Therefore, even though a lot of languages compile to WASM, they usually do it through LLVM or JVM. 
Even so, the aim of thesis being, compiling our typed subset of R directly to WASM, this section will focus on mappings and making typed R work
in WASM. 

\subsection{Type Mapping}

Types are mapped to WebAssembly value types as follows:

\begin{center}
\begin{tabular}{ll}
\hline
\textbf{Source Type} & \textbf{WebAssembly Type} \\
\hline
\texttt{int} & \texttt{i32} \\
\texttt{double} & \texttt{f64} \\
\texttt{logical} & \texttt{i32} (0 = false, 1 = true) \\
\texttt{vector<T>} & \texttt{(ref \$vec\_T)} (struct with data array and length) \\
\texttt{function} & \texttt{(ref \$functype)} (typed function reference) \\
\hline
\end{tabular}
\end{center}

\paragraph{Vector Representation}

Vectors are represented as WebAssembly GC structs:
\begin{lstlisting}[language=wat, caption={Vector struct type}]
(type $vec_f64 (struct
  (field $data (ref (array (mut f64))))
  (field $length (mut i32))
))
\end{lstlisting}

This representation:
\begin{itemize}
    \item Uses WebAssembly GC arrays for efficient storage
    \item Stores length separately for fast access
    \item Allows mutable arrays for in-place updates
    \item Type-specialized structs for different element types (i32, f64, anyref)
\end{itemize}
Moreover, vectors can be constructed through functions embedded into runtime and built-in functions
like \texttt{c, seq, rep}. WASM GC also frees of headache of book-keeping for GC.

\paragraph{Function References}

Functions are represented using WebAssembly typed function references:
\begin{itemize}
    \item Simple functions: Direct \texttt{(ref \$functype)} where \texttt{\$functype} is the function signature
    \item Closures: Struct containing function reference and captured environment
    \item Function calls use \texttt{call\_ref} for indirect calls through function references
\end{itemize}

Closure representation:
\begin{lstlisting}[language=wat, caption={Closure struct type}]
(type $closure (struct
  (field $func (ref $functype))
  (field $env (ref $env_struct))
))
\end{lstlisting}

\subsection{Expression Compilation}

\paragraph{Literals}

Literals compile to immediate value instructions:
\begin{itemize}
    \item Integer literals: \texttt{i32.const n}
    \item Floating-point literals: \texttt{f64.const x}
    \item Boolean literals: \texttt{i32.const 0} (false) or \texttt{i32.const 1} (true)
\end{itemize}

As discussed earlier, R uses vectors even for scalar values. However, for Typed-R, we'll
keep scalar values for better performance.

\paragraph{Variables}

Variable references compile to local or global access:
\begin{itemize}
    \item Local variables: \texttt{local.get \$var\_idx}
    \item Captured variables: Load from closure environment struct
    \item Function references: \texttt{ref.func \$func\_idx}
\end{itemize}

\paragraph{Binary Operations}

Binary operations compile to corresponding WebAssembly instructions:

\begin{itemize}
    \item Integer arithmetic: \texttt{i32.add}, \texttt{i32.sub}, \texttt{i32.mul}, \texttt{i32.div\_s}, \texttt{i32.rem\_s}
    \item Float arithmetic: \texttt{f64.add}, \texttt{f64.sub}, \texttt{f64.mul}, \texttt{f64.div}
    \item Integer comparison: \texttt{i32.eq}, \texttt{i32.ne}, \texttt{i32.lt\_s}, \texttt{i32.le\_s}, \texttt{i32.gt\_s}, \texttt{i32.ge\_s}
    \item Float comparison: \texttt{f64.eq}, \texttt{f64.ne}, \texttt{f64.lt}, \texttt{f64.le}, \texttt{f64.gt}, \texttt{f64.ge}
    \item Logical operations: \texttt{i32.and}, \texttt{i32.or} (with boolean normalization)
\end{itemize}

Vector operations compile to loops that apply scalar operations element-wise:
\begin{enumerate}
    \item Allocate result vector with same length as operands
    \item Loop over indices 0 to length-1
    \item Extract elements from both operand vectors
    \item Apply scalar operation
    \item Store result in result vector
\end{enumerate}
Moreover, all vector operations are written in Typed R language and it's compiled and embedded
into runtime. For example:

\begin{lstlisting}
system_vector_add___vec_int__vec_int <- function(a: vector<int>, b: vector<int>): vector<int> {
    n <- length(a)
    m <- length(b)

    if(n != m & n %% m != 0 & m %% n != 0) {
        stop("Vector lengths not compatible for recycling")
    }

    result_len <- max(n, m)
    result: vector<int> <- vec(length=result_len, mode="int")

    for(i in 1:result_len) {
        a_idx <- ((i - 1) %% n) + 1
        b_idx <- ((i - 1) %% m) + 1
        result[i] <- a[a_idx] + b[b_idx]
    }
    return(result)
}
\end{lstlisting}
Such function is compiled to WASM and the operation vec + vec is mapped to this function name.
\paragraph{Function Calls}

Function calls compile differently based on callee type:

\begin{itemize}
    \item \textbf{Direct calls} (known function): \texttt{call \$func\_idx}
    \item \textbf{Indirect calls} (function variable):
    \begin{enumerate}
        \item Load function reference from local/environment
        \item Evaluate arguments
        \item \texttt{call\_ref \$functype\_idx}
    \end{enumerate}
    \item \textbf{Closure calls}:
    \begin{enumerate}
        \item Load closure struct
        \item Extract environment field
        \item Extract function field
        \item Pass environment as first parameter
        \item Pass regular arguments
        \item \texttt{call\_ref \$closure\_functype\_idx}
    \end{enumerate}
\end{itemize}

\paragraph{If}
Control flows usually are in statements in programming languages. Generally, I treat if as statement
for compilation to WASM but for compiler implementation if is an \texttt{Expr} that can return a value.
Implementation-wise \texttt{if} is represented as follows.
\begin{verbatim}
    If {
        condition: Box<Expr>,
        then_branch: Block,
        else_branch: Option<Block>,
    }
\end{verbatim}
As we explained before, \texttt{Block} can either return \texttt{Expr} or nothing. When \texttt{Expr} is returned
it's important to check if the type returned from then and else branch matches. Then we can go on to return the expression.
The check for the type is done in compile-time so there's no WASM generated check.

\textbf{if} compile to WebAssembly block structures:
\begin{lstlisting}[language=wat, caption={If-else compilation}]
; Evaluate condition
(condition code)

; If-else structure
(if (result ...)
  (then
    ; then-branch code
    ; when expr, just leave the expr on stack
  )
  (else
    ; else-branch code
    ; when expr, just leave the expr on stack
  )
)
\end{lstlisting}
If \texttt{if} returns expression, then it's just left on the stack for the next consumer. Code-gen is quite simple for it.

\subsection{Statement Compilation}

\paragraph{Assignment}

Regular assignment (\texttt{<-}):
\begin{enumerate}
    \item Evaluate right-hand side expression
    \item Store result in local variable: \texttt{local.set \$var\_idx}
\end{enumerate}

Super-assignment (\texttt{<<-}) for captured variables:
\begin{enumerate}
    \item Evaluate right-hand side expression
    \item Load closure environment
    \item Navigate to appropriate nesting level
    \item Extract reference cell for variable
    \item Update cell contents using \texttt{struct.set}
\end{enumerate}

\paragraph{Loops}
Loops are very straight-forward to compile.

\textbf{While loops} compile to loop blocks with conditional branching:
\begin{lstlisting}[language=wat, caption={While loop compilation}]
(block $loop_exit
  (loop $loop_start
    ; Evaluate condition
    (condition code)

    ; Exit if false
    (i32.eqz)
    (br_if $loop_exit)

    ; Loop body
    (body code)

    ; Continue loop
    (br $loop_start)
  )
)
\end{lstlisting}

\textbf{For loops} over ranges compile to indexed loops:
\begin{lstlisting}[language=wat, caption={For loop compilation}]
; Initialize loop variable to start
(local.set $iter (start value))

(block $loop_exit
  (loop $loop_start
    ; Check condition: iter <= end
    (local.get $iter)
    (end value)
    (i32.gt_s)
    (br_if $loop_exit)

    ; Loop body with iter
    (body code)

    ; Increment iter
    (local.get $iter)
    (i32.const 1)
    (i32.add)
    (local.set $iter)

    (br $loop_start)
  )
)
\end{lstlisting}

For loops over vectors use similar structure but load vector elements by index.

\subsection{Function Compilation}
Function compilation is one of the most important. We are taking an environment 
where functions are first-class citizens to static-like function environment in WASM.

For example, how should one compile this?

\begin{lstlisting}[language=R]
        x <- 5L
        f <- function(): int {
            g <- function(): int {
                x + 1L
            }
            g()
        }
\end{lstlisting}

In WASM functions cannot be nested. So we need to propogate the environment information somehow
through the function parameters or maybe in the \texttt{Memory}.
(will write more.)

Function compilation involves multiple steps:

\begin{enumerate}
    \item \textbf{Type registration}: Register function type in type section
    \item \textbf{Function index allocation}: Assign unique function index
    \item \textbf{Local variable allocation}: Determine local variable slots from \texttt{FunctionMetadata}
    \item \textbf{Closure analysis}: Identify captured variables
    \item \textbf{Environment struct generation}: Create struct type for captured variables (if needed)
    \item \textbf{Code generation}: Emit function body
\end{enumerate}

Simple function (no captures):
\begin{lstlisting}[language=wat, caption={Simple function}]
(func $add (param $a i32) (param $b i32) (result i32)
  (local.get $a)
  (local.get $b)
  (i32.add)
)
\end{lstlisting}

Closure function (with captures):
\begin{lstlisting}[language=wat, caption={Closure function}]
(type $env (struct (field $captured_var (mut i32))))

(func $closure_fn (param $env (ref $env)) (param $x i32) (result i32)
  ; Access captured variable
  (local.get $env)
  (struct.get $env $captured_var)

  ; Use parameter
  (local.get $x)

  ; Computation
  (i32.add)
)
\end{lstlisting}

When returning a closure, the compiler:
\begin{enumerate}
    \item Allocates environment struct
    \item Copies captured variable values into struct fields
    \item Allocates closure struct
    \item Stores function reference and environment
    \item Returns closure struct reference
\end{enumerate}

\section{Runtime System}

\subsection{Memory Management}

The runtime uses WebAssembly GC for automatic memory management:
\begin{itemize}
    \item Vectors, strings, and closures are GC-managed heap objects
    \item No explicit deallocation required
    \item WebAssembly GC handles reference counting and garbage collection
    \item Linear memory used for WASI I/O buffers and string serialization
\end{itemize}

Memory layout:
\begin{itemize}
    \item Address 0: Reserved for null pointer checks
    \item Address 8+: WASI I/O buffers for \texttt{fd\_write}
    \item Dynamic region: Managed by compiler for temporary string buffers
\end{itemize}

\subsection{Vector Operations}

Built-in vector operations are compiled to runtime function calls:

\textbf{Vector Construction} (\texttt{c(...)}):
\begin{enumerate}
    \item Determine element type from arguments
    \item Allocate array of appropriate size
    \item Initialize array elements
    \item Allocate vector struct
    \item Store array reference and length
    \item Return vector struct reference
\end{enumerate}

\textbf{Component-wise Operations}:
Vector arithmetic is implemented as inline loops (described previously) rather than runtime calls for performance.

\textbf{Reduction Operations} (\texttt{sum}, \texttt{length}):
\begin{itemize}
    \item \texttt{length}: Extract and return length field from vector struct
    \item \texttt{sum}: Loop over vector elements, accumulating sum
\end{itemize}

\subsection{Built-in Function Implementations}

\paragraph{Print Function}

The \texttt{print} function serializes values to strings and outputs via WASI:
\begin{enumerate}
    \item Convert value to string representation
    \item Write string to linear memory buffer
    \item Call \texttt{fd\_write} to output to stdout (file descriptor 1)
\end{enumerate}

For different types:
\begin{itemize}
    \item Integers: Convert to decimal string
    \item Floats: Convert to decimal string with precision
    \item Strings: Output directly
    \item Vectors: Format as \texttt{[elem1, elem2, ...]}
    \item Booleans: Output \texttt{TRUE} or \texttt{FALSE}
\end{itemize}

\paragraph{Sequence Generation}

The range operator \texttt{start:end} and \texttt{gen\_seq} runtime function:
\begin{enumerate}
    \item Calculate sequence length: \texttt{end - start + 1}
    \item Allocate vector of integers
    \item Fill array with values from \texttt{start} to \texttt{end}
    \item Return vector struct
\end{enumerate}

Optimized implementation uses a simple loop without intermediate allocations.

\subsection{WASI Integration}

The runtime integrates with WASI (WebAssembly System Interface) for I/O:

\begin{itemize}
    \item \textbf{Import}: \texttt{fd\_write} from \texttt{wasi\_snapshot\_preview1}
    \item \textbf{Signature}: \texttt{(i32, i32, i32, i32) -> i32}
    \item \textbf{Parameters}: file descriptor, iovs pointer, iovs length, nwritten pointer
    \item \textbf{Usage}: Output strings to stdout/stderr
\end{itemize}

The \texttt{\_start} function is exported as the entry point, compatible with WASI runtimes like \texttt{wasmtime}.

\section{Implementation Details}

\subsection{Compilation Limitations}

The current implementation represents a proof-of-concept compiler with several deliberate limitations. Most notably, the compiler lacks any exception or error handling mechanism, meaning runtime errors simply terminate execution without graceful recovery. The standard library remains minimal, providing only essential built-in functions like \texttt{print}, \texttt{length}, \texttt{sum}, and vector construction. I/O capabilities are restricted to print output via WASI; file operations and user input are not supported. Type coercion is limited compared to R's flexible type system, supporting only the basic numeric promotion hierarchy (logical $<:$ int $<:$ double). Vector operations cover common arithmetic and indexing but lack many of R's specialized functions like \texttt{apply}, \texttt{sapply}, or statistical operations. List types, while declared in the type system, remain largely unimplemented in the code generator.

\subsection{Design Decisions}

Several architectural decisions shaped the compiler's implementation, each involving trade-offs between performance, simplicity, and compatibility with R semantics. The choice of static typing fundamentally enables efficient ahead-of-time compilation and early error detection, though at the cost of R's dynamic flexibility. This trade-off aligns with the thesis goal of exploring compilation rather than interpretation.

Memory management leverages the WebAssembly GC proposal, which simplifies object lifecycle management and enables efficient heap object representation without manual deallocation. This choice requires newer WebAssembly runtimes but eliminates the complexity of implementing a custom garbage collector or reference counting system. The scoping model follows R's semantics where only functions create scopes while blocks, if-statements, and loops share their enclosing function's scope. This design simplifies closure implementation by avoiding the need to track block-level environments.

For function calls, the compiler uses typed function references rather than function tables. Typed funcrefs enable type-safe indirect calls and eliminate table management overhead, though this feature requires WebAssembly reference types support. Closures are represented as structs containing a function reference and captured environment, providing cleaner semantics than stack manipulation approaches. Variables captured with super-assignment semantics use reference cells (GC structs wrapping mutable values), enabling efficient updates through multiple closure layers.

Vector operations are inlined as loops rather than compiled to runtime function calls. While this increases code size, it improves performance for common element-wise operations by avoiding function call overhead and enabling better optimization by the WebAssembly runtime.

\subsection{Performance Considerations}

The compiler employs several optimization strategies to generate efficient WebAssembly code. Type specialization creates separate vector struct types for i32, f64, and anyref element types, avoiding runtime type checks and enabling more efficient memory layouts. When function call targets are known at compile time, the compiler generates direct \texttt{call} instructions rather than slower indirect \texttt{call\_ref} instructions, reducing call overhead significantly.

Local variable allocation reuses slots for temporary variables when their lifetimes don't overlap, minimizing the function's local declaration section and potentially improving WebAssembly JIT compilation. As discussed earlier, component-wise vector operations are inlined as loops rather than calling runtime functions, trading code size for execution speed. The compiler also caches function signature type indices to avoid recreating identical types in the WebAssembly type section, reducing module size and improving instantiation time. These optimizations focus on low-hanging fruit that provide measurable benefits without requiring complex analysis passes.

