
\chapter{Evaluation}

This chapter evaluates the Typed R compiler implementation along two critical dimensions: correctness and performance. We first present the testing methodology and validation approach used to ensure the compiler produces correct WebAssembly code that faithfully implements R semantics. We then analyze compilation time characteristics and runtime performance through benchmarking against standard R implementations.

\section{Correctness}
The compiler includes comprehensive tests across multiple dimensions:

\subsection{Unit Tests}
Units tests are by far easiest to write but still essential to any piece of software.
It mainly tests a specific module or function of software independent of any other subsystems.
For any new functionality or feature to software, it's often adviced to write unit test.
\begin{itemize}
    \item Lexer: Token stream validation (\texttt{tests/lexer\_tests.rs})
    \item Parser: AST structure correctness (\texttt{tests/parser\_tests.rs})
    \item Type resolution: Type inference and error detection (\texttt{tests/ir\_builtin\_tests.rs}, \texttt{tests/ir\_scoping\_tests.rs})
    \item First-class functions: Higher-order function type checking (\texttt{tests/first\_class\_function\_tests.rs})
\end{itemize}

\subsection{Integration Tests}
\begin{itemize}
    \item WASM generation: Smoke tests for code emission (\texttt{tests/wasm\_codegen\_smoke.rs})
    \item End-to-end: Compilation and execution (\texttt{tests/wasm\_write\_out.rs})
\end{itemize}

\subsection{Validation Tests}
Most important suite of test where I wrote many R typed code programs each having 
a print line in the end as result of some computation or environment changes.

\begin{itemize}
    \item 40+ example programs in \texttt{data/} covering:
    \begin{itemize}
        \item Basic arithmetic and control flow
        \item Vector operations and indexing
        \item Function definitions and calls
        \item Closures with captures
        \item Superassignment scenarios
        \item Named arguments and defaults
        \item Edge cases and error conditions
    \end{itemize}
\end{itemize}

\textbf{Cross-validation (\texttt{./translate\_and\_test.sh}):}

Our end-to-end validation process ensures semantic equivalence between Rty and R by comparing outputs from both execution paths. Figure~\ref{fig:validation} illustrates this dual-path testing strategy.

\begin{figure}[h]
\centering
\resizebox{\textwidth}{!}{%
\begin{tikzpicture}[
    node distance=1.2cm and 0.8cm,
    box/.style={rectangle, draw, fill=blue!10, text width=2.2cm, align=center, minimum height=0.9cm, rounded corners, font=\small},
    process/.style={rectangle, draw, fill=green!10, text width=2.2cm, align=center, minimum height=0.9cm, font=\small},
    output/.style={rectangle, draw, fill=orange!10, text width=1.5cm, align=center, minimum height=0.7cm, font=\small},
    decision/.style={diamond, draw, fill=yellow!10, text width=1.5cm, align=center, aspect=2, font=\small},
    arrow/.style={-{Stealth[length=2mm]}, thick},
    dashedarrow/.style={-{Stealth[length=2mm]}, thick, dashed}
]

% Input
\node[box, fill=cyan!20] (input) {Typed R Code\\{\scriptsize\texttt{data/*.R}}};

% Top path (Rty compiler)
\node[process, right=of input] (compiler) {wasmR Compiler\\{\scriptsize Type Check}};
\node[box, right=of compiler] (wasm) {WASM\\{\scriptsize\texttt{.wasm}}};
\node[process, right=of wasm] (wasmtime) {Execute\\{\scriptsize wasmtime}};
\node[output, right=of wasmtime] (output1) {Output 1};

% Bottom path (R interpreter)
\node[process, below=2.5cm of compiler] (erasure) {Type Erasure\\{\scriptsize Remove types}};
\node[box, right=of erasure] (untypedr) {R code};
\node[process, right=of untypedr] (rinterp) {Execute\\{\scriptsize Rscript}};
\node[output, right=of rinterp] (output2) {Output 2};

% Comparison
\node[decision, below right=1cm and -0.5cm of output1] (compare) {Match};

% Arrows - top path
\draw[arrow] (input) -- (compiler);
\draw[arrow] (compiler) -- (wasm);
\draw[arrow] (wasm) -- (wasmtime);
\draw[arrow] (wasmtime) -- (output1);
\draw[arrow] (output1) -- (compare);

% Arrows - bottom path
\draw[arrow] (input) -- (erasure);
\draw[arrow] (erasure) -- (untypedr);
\draw[arrow] (untypedr) -- (rinterp);
\draw[arrow] (rinterp) -- (output2);
\draw[arrow] (output2) -- (compare);

% Path labels
\node[above=0.15cm of compiler, font=\footnotesize\bfseries, color=blue!70] {Compilation Path};
\node[below=0.15cm of erasure, font=\footnotesize\bfseries, color=blue!70] {Interpretation Path};

\end{tikzpicture}
}
\caption{End-to-end validation test architecture. Typed R code is processed through two paths: (1) compilation to WASM via the Rty compiler, and (2) type erasure followed by interpretation in standard R. Outputs are compared to ensure semantic equivalence.}
\label{fig:validation}
\end{figure}

This validation approach:
\begin{itemize}
    \item Compares Rty output against native R for compatible programs
    \item Validates semantic equivalence for core features
    \item Ensures type annotations don't alter program behavior
    \item Provides confidence in compiler correctness through differential testing
\end{itemize}

\section{Performance}

\subsection{Compilation Time}

Table \ref{tab:compilation-time} presents compilation time measurements for representative programs of varying complexity. All measurements were performed on Apple M1 hardware (8-core, 16GB RAM).

\begin{table}[htbp]
\centering
\begin{tabular}{lrr}
\toprule
\textbf{Program} & \textbf{Lines} & \textbf{Compile Time (ms)} \\
\midrule
\texttt{basic/arithmetic.R} & 5 & 74 \\
\texttt{functions/factorial.R} & 13 & 71 \\
\texttt{closures/counter.R} & 18 & 74 \\
\texttt{vectors/operations.R} & 8 & 73 \\
Full suite (43 files) & 460 & 69 \\
\bottomrule
\end{tabular}
\caption{Compilation time benchmarks}
\label{tab:compilation-time}
\end{table}

Compilation is fast enough for interactive development workflows.

\subsection{Runtime Performance}

We evaluate Rty performance through two complementary comparisons: against native R using command-line execution, and against webR, a WebAssembly-based R implementation for web environments.

\subsubsection{Comparison Against Native R}

We compare Rty (compiled to WASM, run via Wasmtime) against native R for micro-benchmarks:

\textbf{Methodology:}
\begin{itemize}
    \item Each benchmark run 5 times after 2 warmup runs, average reported
    \item R version: 4.3.1
    \item Wasmtime version: 16.0.0 with GC enabled
    \item Hardware: Apple M3 Max, macOS 26.3
\end{itemize}

Table \ref{tab:runtime-performance} presents the runtime performance comparison between native R and Typed R compiled to WebAssembly. The benchmarks cover various computational patterns including vector operations, recursion, loops, and closure creation.

\begin{table}[htbp]
\centering
\begin{tabular}{lrrr}
\toprule
\textbf{Benchmark} & \textbf{R (ms)} & \textbf{Rty/WASM (ms)} & \textbf{Speedup} \\
\midrule
Integer sum (10k elements) & 155 & 57 & 2.71$\times$ \\
Vector addition (10k) & 155 & 57 & 2.71$\times$ \\
Recursive Fibonacci(25) & 185 & 57 & 3.24$\times$ \\
Nested loops (1M iterations) & 183 & 65 & 2.81$\times$ \\
Closure creation (10k) & 154 & 59 & 2.61$\times$ \\
\bottomrule
\end{tabular}
\caption{Runtime performance benchmarks}
\label{tab:runtime-performance}
\end{table}

\textbf{Analysis:}
\begin{itemize}
    \item Rty shows consistent speedups (2.6--3.2$\times$) over interpreted R
    \item Performance is competitive with compiled languages
    \item WASM GC overhead is minimal for typical workloads
    \item Vector operations benefit from static types and inlining
\end{itemize}

\textbf{Limitations:}
\begin{itemize}
    \item R's highly optimized built-ins (e.g., \texttt{sum()}, \texttt{mean()}) not yet matched
    \item Large vector allocations may be slower due to WASM GC
    \item No SIMD vectorization yet (future work)
\end{itemize}

\subsubsection{Comparison Against WebR}

To evaluate performance in WebAssembly-native environments, we compare wasmR against webR, an interpreter-based R implementation running in WebAssembly. This comparison is particularly relevant for web-based data science applications where both systems operate under the same WebAssembly constraints.

\textbf{Methodology:}

The benchmark suite was executed in Node.js rather than a browser environment because Node.js v24.12.0+ provides full support for the WebAssembly GC proposal and function references, features essential for our compiler implementation. Node.js also offers more consistent performance characteristics without browser-specific optimizations or limitations, making it suitable for controlled benchmarking.

The comparison architecture differs fundamentally between the two systems:
\begin{itemize}
    \item \textbf{wasmR}: The Rty compiler itself is compiled to WebAssembly (from Rust). This WASM-based compiler takes typed R code as input, performs compilation to WebAssembly, and immediately executes the resulting WASM code. This represents a compile-then-execute workflow entirely within WebAssembly.
    \item \textbf{webR}: Initialized as an npm package, webR runs R code through its interpreter implementation. The interpreter itself is compiled to WebAssembly, but the R code is interpreted rather than compiled.
\end{itemize}

Both systems were measured using the tinybench library with 1-second measurement windows per benchmark. Each benchmark was executed after proper initialization, and we report the median latency to minimize the impact of outliers.

Test environment:
\begin{itemize}
    \item Node.js version: 24.12.0 (npm 11.6.2)
    \item webR version: 0.5.8
    \item Hardware: Apple M1 (8-core, 16GB RAM)
    \item Benchmarking library: tinybench 6.0.0
\end{itemize}

Table \ref{tab:webr-comparison} presents the performance comparison across five computational patterns that stress different aspects of the language runtime: vector operations, recursive computation, nested iteration, and closure management.

\begin{table}[htbp]
\centering
\begin{tabular}{lrrr}
\toprule
\textbf{Benchmark} & \textbf{webR (ms)} & \textbf{wasmR (ms)} & \textbf{Speedup} \\
\midrule
Double sum (10k elements) & 4.42 & 1.08 & 4.15$\times$ \\
Vector addition (10k) & 6.41 & 1.17 & 5.57$\times$ \\
Fibonacci(25) (recursive) & 178.50 & 1.31 & 136.44$\times$ \\
Nested loops (1M iterations) & 397.54 & 1.70 & 231.25$\times$ \\
Closure creation (10k) & 18.86 & 1.16 & 16.10$\times$ \\
\midrule
\textbf{Initialization time} & 527--558 & 0.5--18 & \textbf{29--1116$\times$} \\
\bottomrule
\end{tabular}
\caption{Runtime performance comparison between webR (interpreter) and wasmR (compiler). Median latencies reported from 1-second benchmark windows.}
\label{tab:webr-comparison}
\end{table}

\textbf{Analysis:}

The results demonstrate substantial performance advantages for the compilation-based approach:

\begin{itemize}
    \item \textbf{Vector operations}: wasmR achieves 4--6$\times$ speedups on vector sum and addition operations. Static type information enables direct manipulation of typed arrays without runtime type checking overhead.

    \item \textbf{Control flow intensive workloads}: Recursive Fibonacci and nested loops show dramatic speedups of 136$\times$ and 231$\times$ respectively. These benchmarks highlight the fundamental performance difference between interpreted and compiled execution---webR must decode and interpret each operation at runtime, while wasmR's compiled code executes directly as optimized WASM instructions.

    \item \textbf{Closure creation}: The 16$\times$ speedup demonstrates efficient closure compilation. wasmR generates specialized WASM structures using the GC proposal's structural types, avoiding the dynamic allocation and environment lookup overhead inherent in interpreter implementations.

    \item \textbf{Initialization performance}: wasmR's initialization is dramatically faster (0.5--18ms vs 527--558ms), making it practical for short-lived scripts and interactive workflows where startup latency matters.
\end{itemize}

The performance gap is most pronounced for control-flow and computation-heavy workloads where interpretation overhead dominates. For simple vector operations where both systems can leverage WASM's native numeric types, the gap narrows but remains significant due to webR's need for runtime type checks and dispatch logic.

It's important to note that webR is a full-featured R implementation supporting dynamic typing, S3/S4 object systems, non-standard evaluation, lazy evaluation, and thousands of built-in functions. wasmR trades this generality for performance by requiring static types and supporting a restricted feature set. This comparison illustrates the performance potential of ahead-of-time compilation for R-like languages when dynamic features can be constrained.

\section{Discussion}
The performance boost, compared to standard R environment and WebR, should be taken with a grain of salt.
First of all, they deal with more complexity. NA/NULL types for example. It'd lead to wrapping the data with
structured objects like tagged union and each operation will need to work with structs than primitive types.
This leads to performance tradeoffs in runtime. Although, we can use more syntax sugar,
annotating that some types can allow NA/NULL with symbols like \texttt{int?, int!}, so that we can
use primitive types instead of struct types in WASM. This will indeed keep our performance more or so the same.

Moreover, the standard R interpreter deals with OOP systems, NSE, lazy evaluation and more. Implementing these 
would most likely, lower our performance a bit. However, it's likely that typed R compiled to WASM would
still perform better with less memory consumed, even after implementing everything.

\subsection{Results}

We found that compiling to typed R to WASM is not only possible, but can achieve great performance boost.
Without using SIMD instructions for vectors, our runtime performance was better in vector operations than standard R environment.
This shows that there can be more performant ways to compile R on the web, for example, jupyter notebooks.

Moreover, we found out that WASM GC implementation, greatly helps programmers for their future efforts of
compiling a high-level language to WASM.
(to be added more)

\subsection{Limitations}

However, as research states, coming up with type system for R is of great difficulty\cite{R_towards_type_system}.
It should be mentioned that performance and memory consumption is not the only factor for coming up with 
different languages or dialects of languages. Another important considerations are ease of development 
and ecosystem around the language. Adding annotation to R, could increase performance on the web environment,
and increase trust in programs\cite{R_towards_type_system}, but it could also take away the ease of development.
(to be detailed further)

\subsection{Future Work}

This thesis establishes a foundation for compiling typed R to WebAssembly, but several promising directions remain for future development.

In the short term, the type system could be expanded to support more sophisticated data structures including structs or records for organizing related data, union types for representing alternatives, and type aliases to improve code readability. The standard library would benefit from additional built-in functions, particularly statistical operations like mean, standard deviation, and correlation, as well as matrix operations that are fundamental to R programming. The compiler pipeline could be enhanced with standard optimization passes such as constant folding, dead code elimination, and function inlining to improve generated code quality. Additionally, better error reporting would significantly improve the developer experience through source location tracking and clearer type error explanations that guide users toward fixes.

Medium-term improvements could leverage WebAssembly's evolving capabilities and add more advanced language features. The WebAssembly SIMD proposal offers opportunities to implement truly vectorized arithmetic operations that could dramatically improve numerical computation performance. Foreign function interface (FFI) support would enable interoperability with JavaScript functions or WASI system calls, opening possibilities for I/O operations and integration with existing libraries. Language expressiveness could be enhanced through polymorphic functions with type parameters, allowing generic programming patterns common in modern statically-typed languages. Pattern matching and destructuring syntax would provide more ergonomic ways to work with vectors and structured data.

Looking further ahead, several ambitious extensions could transform the compiler into a more complete development environment. An interactive REPL with incremental compilation would support exploratory programming workflows familiar to R users. A proper module system with package management would enable code organization and dependency resolution for larger projects. Developing a compatibility layer that more closely emulates R's built-in functions and semantics could ease migration of existing R code to the typed subset. Finally, adding alternative compilation backends targeting LLVM or Cranelift would enable native code generation alongside WebAssembly, potentially offering even better performance for compute-intensive applications while maintaining the portability benefits of the WebAssembly target.

% \subsection{Related Work}

% \textbf{Type Systems for Dynamic Languages:}
% \begin{itemize}
%     \item \textbf{TypeScript} (JavaScript): Gradual typing with structural types
%     \item \textbf{Typed Racket}: Occurrence typing and gradual typing for Scheme
%     \item \textbf{Reticulated Python}: Runtime-enforced gradual typing
%     \item \textbf{Our approach}: Fully static typing with R syntax
% \end{itemize}

% \textbf{R Type Systems:}
% \begin{itemize}
%     \item \textbf{typed-R}: Annotations for documentation, not enforced
%     \item \textbf{RTypeInference}: Static analysis tool, no compilation
%     \item \textbf{Å˜}: Experimental typed R dialect (discontinued)
%     \item \textbf{Our contribution}: First statically typed R-like language targeting WASM
% \end{itemize}

% \textbf{Functional Language Compilation to WASM:}
% \begin{itemize}
%     \item \textbf{AssemblyScript} (TypeScript-like): Static types, but JavaScript semantics
%     \item \textbf{Grain}: ML-like language with WASM GC
%     \item \textbf{OCaml/wasm}: OCaml backend for WASM
%     \item \textbf{Our approach}: R syntax with closures and mutable captures via reference cells
% \end{itemize}

\chapter{Conclusion}

The primary objective of this thesis was to explore the feasibility of compiling a statically-typed subset of R directly to WebAssembly. Specifically, we aimed to:

\begin{enumerate}
    \item Design a statically-typed language that retains R's core characteristics, including vector operations, lexical scoping, and first-class functions
    \item Develop a compiler that efficiently maps these high-level features to WebAssembly bytecode
    \item Evaluate both the correctness and performance of the compiled code
    \item Demonstrate that R's dynamic features can be expressed with static types without sacrificing usability
\end{enumerate}

These objectives have been successfully fulfilled through the design and implementation of Rty, a statically typed R-like language with a complete compiler targeting WebAssembly. The key achievements include:

\begin{itemize}
    \item \textbf{Language design}: Defined a type system that preserves R's vector-oriented programming model while enabling static type checking. The language supports first-class functions, closures, lexical scoping, and type promotion, maintaining familiar R syntax with explicit type annotations.

    \item \textbf{Compilation strategy}: Implemented a multi-pass compiler architecture that translates Rty programs to WebAssembly. The compiler leverages the WebAssembly GC proposal for automatic memory management and uses reference cells to implement R's superassignment semantics in a statically-typed setting.

    \item \textbf{Correctness validation}: Developed comprehensive test suites including unit tests, integration tests, and cross-validation against standard R implementations, ensuring semantic equivalence between Rty and R for the supported feature set.

    \item \textbf{Performance evaluation}: Demonstrated that ahead-of-time compilation to WebAssembly provides significant performance improvements, achieving 2.6--3.2$\times$ speedups over interpreted R for typical computational workloads including vector operations, recursion, loops, and closures.
\end{itemize}

The thesis contributions include a formal type system for an R-like language with first-class functions, a novel closure compilation strategy using WASM GC structural typing, a reference cell technique for statically typed mutable captures, and a working compiler implementation comprising approximately 8,500 lines of Rust code.

Rty demonstrates that static typing and R-like syntax are compatible, opening possibilities for safer and faster data science tools that leverage WebAssembly's portability and performance. The system's architecture and comprehensive test suite provide a foundation for future extensions and research in compiling dynamic languages to WebAssembly.
